{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f6Lpk7wrCl8q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/dip07/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/dip07/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "2025-12-04 10:19:22.873693: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-04 10:19:22.914451: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-04 10:19:24.048860: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scripts.pre_process_dataset import PreProcess\n",
    "from scripts.import_dataset import ImportDataset\n",
    "from scripts.plots import PlotReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GlobalMaxPooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "# mpl.rcParams[\"text.usetex\"] = True\n",
    "mpl.rcParams['font.family'] = 'serif'\n",
    "mpl.rcParams['font.size'] = 16\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9jA9v1OC3AK",
    "outputId": "1f4b33cf-db7e-4cf9-ef23-d8b234d2863d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined dataset size: 14438 samples\n"
     ]
    }
   ],
   "source": [
    "data = ImportDataset()\n",
    "df = data.read_dataset()\n",
    "print(f\"✅ Combined dataset size: {df.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WhCOM9cDC3DK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition_label</th>\n",
       "      <th>medical_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tissue change around loose prosthesis canine m...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   condition_label                                   medical_abstract\n",
       "0                0  tissue change around loose prosthesis canine m..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df = PreProcess(df)\n",
    "df = clean_df.preprocess_dataset()\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 10106\n",
      "Validation set size: 4332\n"
     ]
    }
   ],
   "source": [
    "X = df['medical_abstract']\n",
    "y = df['condition_label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Validation set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J2sdWdKjDcs0",
    "outputId": "c8bafb58-9839-45c5-d510-8ed6924a1a73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: 5000, Max Length: 200\n",
      "Train shape: (10106, 200)\n"
     ]
    }
   ],
   "source": [
    "# Settings\n",
    "MAX_WORDS = 5000\n",
    "MAX_LEN = 200\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post')\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "\n",
    "# Class weights\n",
    "class_weights_array = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = {i: class_weights_array[i] for i in range(5)}\n",
    "print(f\"Vocab: {MAX_WORDS}, Max Length: {MAX_LEN}\")\n",
    "print(f\"Train shape: {X_train_pad.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TK9HJFsDIjH7"
   },
   "source": [
    "# Build, Train, and Evaluate LSTM Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvZQm5jVDraJ",
    "outputId": "829a5141-831d-48d8-acc0-5b6f67058baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 10:19:35.628773: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 113ms/step - accuracy: 0.2626 - loss: 1.7549 - val_accuracy: 0.3877 - val_loss: 1.6803\n",
      "Epoch 2/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.4041 - loss: 1.5223 - val_accuracy: 0.5114 - val_loss: 1.3866\n",
      "Epoch 3/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.5000 - loss: 1.3504 - val_accuracy: 0.5262 - val_loss: 1.2833\n",
      "Epoch 4/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 109ms/step - accuracy: 0.5280 - loss: 1.2629 - val_accuracy: 0.5232 - val_loss: 1.2356\n",
      "Epoch 5/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 107ms/step - accuracy: 0.5403 - loss: 1.2129 - val_accuracy: 0.5237 - val_loss: 1.2180\n",
      "Epoch 6/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 113ms/step - accuracy: 0.5501 - loss: 1.1746 - val_accuracy: 0.5203 - val_loss: 1.1931\n",
      "Epoch 7/20\n",
      "\u001b[1m127/127\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 108ms/step - accuracy: 0.5727 - loss: 1.1233 - val_accuracy: 0.5213 - val_loss: 1.2061\n",
      "Epoch 8/20\n",
      "\u001b[1m 46/127\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 100ms/step - accuracy: 0.5814 - loss: 1.0769"
     ]
    }
   ],
   "source": [
    "# Build LSTM\n",
    "model_lstm = Sequential([\n",
    "    Embedding(MAX_WORDS, 64, input_length=MAX_LEN),\n",
    "    LSTM(32, return_sequences=True, dropout=0.2),\n",
    "    GlobalMaxPooling1D(),\n",
    "    Dense(16, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    Dropout(0.5),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "model_lstm.compile(\n",
    "    optimizer=keras.optimizers.Adam(0.0005),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_lstm = model_lstm.fit(\n",
    "    X_train_pad, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "# y_pred_lstm = np.argmax(model_lstm.predict(X_test_pad, verbose=0), axis=1)\n",
    "# acc_lstm = accuracy_score(y_test, y_pred_lstm)\n",
    "# print(f\"\\nLSTM Accuracy: {acc_lstm:.4f} ({acc_lstm*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model_lstm.evaluate(X_test_pad, y_test)\n",
    "print(\"Accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H1OnJmL-I989"
   },
   "source": [
    "# Classification Reports of the RNN Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eIUQon4iEpPI",
    "outputId": "5e4d2646-838c-446d-b1ad-eff20c3554e5"
   },
   "outputs": [],
   "source": [
    "# Classification report for LSTM\n",
    "# print(\"\\n LSTM Classification Report \")\n",
    "# print(classification_report(y_test, y_pred_lstm, target_names=[f'class_{i}' for i in range(5)]))\n",
    "\n",
    "plot = PlotReport(model_lstm, X_test_pad, y_test)\n",
    "plot.get_confusion_matrix(True)\n",
    "plot.print_confusion_matrix(\"Confusion_RNN.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ya5Fyd7gI6XU"
   },
   "source": [
    "# Visualize Model Performance and Training Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "i1rUSe3ZEPtL",
    "outputId": "851e4d4b-ba89-4044-ed76-12735403abc1"
   },
   "outputs": [],
   "source": [
    "# Graph 1: Model Comparison\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "ax.plot(history_lstm.history['accuracy'], label='Train', linewidth=2)\n",
    "ax.plot(history_lstm.history['val_accuracy'], label='Validation', linewidth=2)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('LSTM Training History', fontsize=13, fontweight='bold')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.suptitle('RNN Models Performance Analysis', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.read_csv(\"data/medical_tc_labels.csv\")\n",
    "df_labels.loc[df_labels['condition_label'] == 5, 'condition_label'] = 0\n",
    "df_labels['name'] = df_labels['condition_name'].str.split(n=1, expand=True)[0]\n",
    "df_labels = df_labels.sort_values(by='condition_label')\n",
    "df_labels"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
